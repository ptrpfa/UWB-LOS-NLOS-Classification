{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the preprocessing conducted, we have selected the following datasets to conduct an evaluation to determine which dataset will be used before performing hyperparameter tuning on our desired dataset.\n",
    "\n",
    "The datasets that we have chosen are:\n",
    "- `noncir_ss_scaled_trimmed_cir_pca_ss_scaled.pkl`: Non-Cir (Standard Scaled after feature selection) with CIR Statistical Measures (PCA and Standard Scaled)\n",
    "- `noncir_ss_scaled_trimmed_cir_ss_scaled.pkl`: Non-CIR (Standard Scaled after feature selection) with CIR Statistical Measures (Standard Scaled)\n",
    "- `noncir_ss_scaled_trimmed_cir_pca.pkl`: Non-CIR (Standard Scaled after feature selection) with CIR Statistical Measures (PCA)\n",
    "\n",
    "The datasets will be loaded into `dataset_1`, `dataset_2`, `dataset_3` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_1 = load_from_pickle(\"noncir_ss_scaled_trimmed_cir_pca_ss_scaled.pkl\")\n",
    "dataset_2 = load_from_pickle(\"noncir_ss_scaled_trimmed_cir_ss_scaled.pkl\")\n",
    "dataset_3 = load_from_pickle(\"noncir_ss_scaled_trimmed_cir_pca.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 (noncir_ss_scaled_trimmed_cir_pca_ss_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the performance of `dataset_1`. With a 70:30 training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the features to be used for Support Vector Classification\n",
    "X = dataset_1.drop(columns = 'NLOS')\n",
    "Y = dataset_1[['NLOS']].to_numpy()\n",
    "Y = Y.reshape(-1)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into 70% training and 30% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, Y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for MLPClassifier\n",
    "\n",
    "The hyperparameter tuning helps to test all the various combinations that we have defined within the parameter space and provides the parameters that provides the most optimal results.\n",
    "\n",
    "To determine the most optimal parameters for the MLP Classifier, we will conduct Hyperparameter tuning using GridSearchCV.\n",
    "\n",
    "The following are the parameters that we will be tuning:\n",
    "- `hidden_layer_sizes`\n",
    "    - Determines the number of neurons in the ith hidden layer (E.g. (10, 10) Represents 10 neurons in 2 hidden layers)\n",
    "- `activation`\n",
    "    - Activation function for the hidden layer\n",
    "        - `tanh` Hyperbolic tan function, returns f(x) = tanh(x)\n",
    "        - `relu` Rectified linear unit function, returns f(x) = max(0, x)\n",
    "- `solver`\n",
    "    - Solver for weight optimization\n",
    "        - `adam` Stochastic gradient-based optimiser proposed by Kingma, Diederik, and Jimmy Ba\n",
    "        - `sgd` Stochastic gradient descent\n",
    "- `alpha`\n",
    "    - Strength of the L2 regularization term aka penalty term, that combats overfitting by constraining the size of the weights. Increasing alpha may fix high variance (a sign of overfitting) by encouraging smaller weights, resulting in a decision boundary plot that appears with lesser curvatures. Similarly, decreasing alpha may fix high bias (a sign of underfitting) by encouraging larger weights, potentially resulting in a more complicated decision boundary.\n",
    "- `learning_rate`\n",
    "    - Learning rate schedule for weight updates\n",
    "        - `constant` Constant learning rate given by default which is 0.001\n",
    "        - `adaptive` Keeps the learning rate constant to default 0.001 if the training loss keeps decreasing but for every 2 consecutive epochs fail to decrease the training loss, the current learning rate is divided by 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mlp \u001b[38;5;241m=\u001b[39m \u001b[43mMLPClassifier\u001b[49m(max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      3\u001b[0m parameter_space \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layer_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: [(\u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m ,\u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m), (\u001b[38;5;241m100\u001b[39m)],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter = 1000)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50), (50, 50), (50, 50, 50), (50, 100, 50), (100, 100, 100), (50, 50 ,50), (50, 50, 50, 50), (100, 100, 100, 100), (100, 100), (100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearchCV will be configured with the following parameters:\n",
    "- `cv`\n",
    "    - Cross Validation spliting strategy where the value determine the number of folds.\n",
    "- `n_jobs`\n",
    "    - Number of jobs to run in parallel (Determines how many processors to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/cezaartan/Desktop/University/SIT/CSC3105 - Data Analytics/CSC3105-DA-T2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# CV (Cross Validation) helps to split our dataset into random groups and have 1 group being the test dataset whilst the rest are used for training - Helps to reduce overfitting\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs = 1, cv = 3, verbose = 3)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters Found: \\n\", clf.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(clf.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the mean, sd and paremeters of the training scores\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(activation = 'relu', solver = 'adam', hidden_layer_sizes = (50), random_state = 12, max_iter = 1000)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "save_to_pickle(f'{MODEL_FOLDER}/mlp_optimised.pkl', clf, complete_path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy: %.4f\" % accuracy_score(y_train, y_train_pred))\n",
    "print(\"Testing Accuracy: %.4f\" % accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_metrics(list(y_train), y_train_pred, print_results = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics of the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_metrics(list(y_test), y_test_pred, print_results = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report of the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = clf.predict(x_train)\n",
    "cm = confusion_matrix(y_train, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve of MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
